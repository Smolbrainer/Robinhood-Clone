#!/usr/bin/env python3
"""
Advanced Stock Prediction API
Uses sophisticated technical analysis with multiple indicators
More advanced than simple_app.py but doesn't require TensorFlow
"""

import os
import sys
import time
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional

import yfinance as yf
import pandas as pd
import numpy as np
from flask import Flask, jsonify, request
from flask_cors import CORS
import ta
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error
import warnings
warnings.filterwarnings('ignore')

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Flask app setup
app = Flask(__name__)
CORS(app)

# Global cache for predictions
CACHE = {}
CACHE_DURATION = 24 * 60 * 60  # 24 hours in seconds

class AdvancedStockPredictor:
    def __init__(self):
        self.scaler = StandardScaler()
        self.model = RandomForestRegressor(
            n_estimators=100,
            max_depth=10,
            random_state=42
        )
        
    def fetch_data(self, symbol: str, period: str = "2y") -> pd.DataFrame:
        """Fetch stock data with comprehensive error handling"""
        try:
            ticker = yf.Ticker(symbol)
            df = ticker.history(period=period)
            
            if df.empty:
                raise ValueError(f"No data found for {symbol}")
                
            # Ensure we have enough data
            if len(df) < 100:
                raise ValueError(f"Insufficient data for {symbol}: {len(df)} days")
                
            return df
            
        except Exception as e:
            logger.error(f"Error fetching data for {symbol}: {e}")
            raise
    
    def calculate_advanced_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """Calculate comprehensive technical indicators"""
        try:
            # Price indicators
            df['sma_10'] = ta.trend.sma_indicator(df['Close'], window=10)
            df['sma_20'] = ta.trend.sma_indicator(df['Close'], window=20)
            df['sma_50'] = ta.trend.sma_indicator(df['Close'], window=50)
            df['sma_200'] = ta.trend.sma_indicator(df['Close'], window=200)
            
            df['ema_12'] = ta.trend.ema_indicator(df['Close'], window=12)
            df['ema_26'] = ta.trend.ema_indicator(df['Close'], window=26)
            
            # Bollinger Bands
            bollinger = ta.volatility.BollingerBands(df['Close'])
            df['bb_high'] = bollinger.bollinger_hband()
            df['bb_low'] = bollinger.bollinger_lband()
            df['bb_width'] = bollinger.bollinger_wband()
            df['bb_percent'] = bollinger.bollinger_pband()
            
            # RSI
            df['rsi'] = ta.momentum.rsi(df['Close'], window=14)
            df['rsi_30'] = 30
            df['rsi_70'] = 70
            
            # MACD
            macd = ta.trend.MACD(df['Close'])
            df['macd'] = macd.macd()
            df['macd_signal'] = macd.macd_signal()
            df['macd_histogram'] = macd.macd_diff()
            
            # Stochastic Oscillator
            stoch = ta.momentum.StochasticOscillator(df['High'], df['Low'], df['Close'])
            df['stoch_k'] = stoch.stoch()
            df['stoch_d'] = stoch.stoch_signal()
            
            # Average True Range (Volatility)
            df['atr'] = ta.volatility.average_true_range(df['High'], df['Low'], df['Close'])
            
            # Volume indicators
            df['volume_sma'] = df['Volume'].rolling(window=20).mean()
            df['volume_ratio'] = df['Volume'] / df['volume_sma']
            
            # On Balance Volume
            df['obv'] = ta.volume.on_balance_volume(df['Close'], df['Volume'])
            
            # Commodity Channel Index
            df['cci'] = ta.trend.cci(df['High'], df['Low'], df['Close'], window=20)
            
            # Williams %R
            df['williams_r'] = ta.momentum.williams_r(df['High'], df['Low'], df['Close'])
            
            # Price rate of change
            df['roc'] = ta.momentum.roc(df['Close'], window=12)
            
            # Momentum indicators
            df['momentum_1w'] = df['Close'].pct_change(5)
            df['momentum_1m'] = df['Close'].pct_change(20)
            df['momentum_3m'] = df['Close'].pct_change(60)
            
            # Volatility
            df['volatility_10d'] = df['Close'].rolling(10).std()
            df['volatility_30d'] = df['Close'].rolling(30).std()
            
            return df
            
        except Exception as e:
            logger.error(f"Error calculating indicators: {e}")
            raise
    
    def prepare_features(self, df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:
        """Prepare features for machine learning"""
        try:
            # Select feature columns
            feature_cols = [
                'sma_10', 'sma_20', 'sma_50', 'sma_200',
                'ema_12', 'ema_26',
                'bb_high', 'bb_low', 'bb_width', 'bb_percent',
                'rsi', 'macd', 'macd_signal', 'macd_histogram',
                'stoch_k', 'stoch_d', 'atr', 'volume_ratio',
                'obv', 'cci', 'williams_r', 'roc',
                'momentum_1w', 'momentum_1m', 'momentum_3m',
                'volatility_10d', 'volatility_30d'
            ]
            
            # Create features matrix
            features = df[feature_cols].copy()
            
            # Create target (next day's closing price)
            target = df['Close'].shift(-1)
            
            # Remove rows with NaN values
            mask = ~(features.isnull().any(axis=1) | target.isnull())
            features = features[mask]
            target = target[mask]
            
            if len(features) < 50:
                raise ValueError("Insufficient clean data for training")
            
            return features.values, target.values
            
        except Exception as e:
            logger.error(f"Error preparing features: {e}")
            raise
    
    def train_and_predict(self, symbol: str) -> Dict:
        """Train model and make predictions"""
        try:
            # Fetch data
            df = self.fetch_data(symbol)
            current_price = float(df['Close'].iloc[-1])
            
            # Calculate indicators
            df = self.calculate_advanced_indicators(df)
            
            # Prepare features
            X, y = self.prepare_features(df)
            
            # Split data for training (use 80% for training)
            split_idx = int(len(X) * 0.8)
            X_train, X_test = X[:split_idx], X[split_idx:]
            y_train, y_test = y[:split_idx], y[split_idx:]
            
            # Scale features
            X_train_scaled = self.scaler.fit_transform(X_train)
            X_test_scaled = self.scaler.transform(X_test)
            
            # Train model
            self.model.fit(X_train_scaled, y_train)
            
            # Evaluate model
            y_pred = self.model.predict(X_test_scaled)
            mae = mean_absolute_error(y_test, y_pred)
            rmse = np.sqrt(mean_squared_error(y_test, y_pred))
            accuracy = 1 - (mae / np.mean(y_test))
            
            # Make future predictions
            predictions = []
            dates = []
            confidence_upper = []
            confidence_lower = []
            
            # Use last known features for prediction
            last_features = X[-1:].copy()
            last_features_scaled = self.scaler.transform(last_features)
            
            current_date = datetime.now()
            
            for i in range(365):  # Predict 1 year ahead
                # Predict next price
                pred_price = self.model.predict(last_features_scaled)[0]
                
                # Calculate confidence intervals based on model uncertainty
                confidence_range = mae * 1.96  # 95% confidence interval
                upper_bound = pred_price + confidence_range
                lower_bound = pred_price - confidence_range
                
                predictions.append(float(pred_price))
                confidence_upper.append(float(upper_bound))
                confidence_lower.append(float(lower_bound))
                
                # Generate business day
                next_date = current_date + timedelta(days=i+1)
                if next_date.weekday() < 5:  # Monday = 0, Friday = 4
                    dates.append(next_date.strftime('%Y-%m-%d'))
                
                # Update features for next prediction (simplified)
                # In practice, you'd update with actual new indicator values
                if len(dates) >= 365:
                    break
            
            # Calculate trend analysis
            price_1y = predictions[-1] if predictions else current_price
            return_1y = (price_1y - current_price) / current_price
            
            if return_1y > 0.2:
                trend = "strongly_bullish"
            elif return_1y > 0.1:
                trend = "bullish"
            elif return_1y > -0.1:
                trend = "neutral"
            elif return_1y > -0.2:
                trend = "bearish"
            else:
                trend = "strongly_bearish"
            
            # Get latest indicator values for display
            latest_indicators = {
                'sma_10': float(df['sma_10'].iloc[-1]) if not pd.isna(df['sma_10'].iloc[-1]) else None,
                'sma_20': float(df['sma_20'].iloc[-1]) if not pd.isna(df['sma_20'].iloc[-1]) else None,
                'sma_50': float(df['sma_50'].iloc[-1]) if not pd.isna(df['sma_50'].iloc[-1]) else None,
                'sma_200': float(df['sma_200'].iloc[-1]) if not pd.isna(df['sma_200'].iloc[-1]) else None,
                'rsi': float(df['rsi'].iloc[-1]) if not pd.isna(df['rsi'].iloc[-1]) else None,
                'macd': float(df['macd'].iloc[-1]) if not pd.isna(df['macd'].iloc[-1]) else None,
                'bb_percent': float(df['bb_percent'].iloc[-1]) if not pd.isna(df['bb_percent'].iloc[-1]) else None,
                'volume_ratio': float(df['volume_ratio'].iloc[-1]) if not pd.isna(df['volume_ratio'].iloc[-1]) else None,
                'volatility_30d': float(df['volatility_30d'].iloc[-1]) if not pd.isna(df['volatility_30d'].iloc[-1]) else None,
                'momentum_1m': float(df['momentum_1m'].iloc[-1]) if not pd.isna(df['momentum_1m'].iloc[-1]) else None,
            }
            
            return {
                'symbol': symbol,
                'current_price': current_price,
                'predicted_1y_price': price_1y,
                'predicted_return': return_1y,
                'trend': trend,
                'model_accuracy': float(accuracy),
                'model_mae': float(mae),
                'model_rmse': float(rmse),
                'predictions': predictions[:365],
                'dates': dates[:365],
                'upper_bound': confidence_upper[:365],
                'lower_bound': confidence_lower[:365],
                'technical_indicators': latest_indicators,
                'prediction_date': datetime.now().isoformat(),
                'confidence_score': min(accuracy * 100, 95.0)  # Cap at 95%
            }
            
        except Exception as e:
            logger.error(f"Error in prediction for {symbol}: {e}")
            raise

# Initialize predictor
predictor = AdvancedStockPredictor()

@app.route('/health', methods=['GET'])
def health_check():
    """Health check endpoint"""
    return jsonify({
        'service': 'Advanced Stock Prediction API',
        'status': 'healthy',
        'model': 'Random Forest with Advanced Technical Analysis',
        'features': '25+ technical indicators'
    })

@app.route('/predict/<symbol>', methods=['GET'])
def predict_stock(symbol):
    """Advanced prediction endpoint"""
    try:
        symbol = symbol.upper()
        cache_key = f"advanced_{symbol}"
        
        # Check cache
        if cache_key in CACHE:
            cache_data = CACHE[cache_key]
            if time.time() - cache_data['timestamp'] < CACHE_DURATION:
                logger.info(f"Returning cached prediction for {symbol}")
                return jsonify({
                    'success': True,
                    'cached': True,
                    'data': cache_data['data']
                })
        
        # Generate new prediction
        logger.info(f"Generating advanced prediction for {symbol}")
        start_time = time.time()
        
        prediction_data = predictor.train_and_predict(symbol)
        
        # Cache result
        CACHE[cache_key] = {
            'data': prediction_data,
            'timestamp': time.time()
        }
        
        end_time = time.time()
        logger.info(f"Advanced prediction for {symbol} completed in {end_time - start_time:.2f} seconds")
        
        return jsonify({
            'success': True,
            'cached': False,
            'data': prediction_data,
            'processing_time': round(end_time - start_time, 2)
        })
        
    except Exception as e:
        logger.error(f"Prediction error for {symbol}: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/cache/status', methods=['GET'])
def cache_status():
    """Get cache status"""
    return jsonify({
        'cached_symbols': list(CACHE.keys()),
        'cache_count': len(CACHE),
        'cache_duration_hours': CACHE_DURATION / 3600
    })

@app.route('/cache/clear', methods=['POST'])
def clear_cache():
    """Clear prediction cache"""
    global CACHE
    CACHE.clear()
    return jsonify({'message': 'Cache cleared successfully'})

@app.route('/predict-batch', methods=['POST'])
def predict_batch():
    """Batch prediction endpoint"""
    try:
        data = request.get_json()
        symbols = data.get('symbols', [])
        
        if not symbols:
            return jsonify({'error': 'No symbols provided'}), 400
        
        results = {}
        for symbol in symbols:
            try:
                symbol = symbol.upper()
                prediction_data = predictor.train_and_predict(symbol)
                results[symbol] = {
                    'success': True,
                    'data': prediction_data
                }
            except Exception as e:
                results[symbol] = {
                    'success': False,
                    'error': str(e)
                }
        
        return jsonify(results)
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    print("ðŸš€ Starting Advanced Stock Prediction API...")
    print("ðŸŒ Server running at: http://localhost:5000")
    print("ðŸ“Š Features:")
    print("  â€¢ Random Forest machine learning model")
    print("  â€¢ 25+ advanced technical indicators")
    print("  â€¢ Bollinger Bands, RSI, MACD, Stochastic")
    print("  â€¢ Volume analysis and momentum indicators")
    print("  â€¢ Model accuracy scoring")
    print("  â€¢ 1-year detailed forecasting")
    print("  â€¢ Confidence intervals")
    print("  â€¢ Real-time caching")
    print()
    print("ðŸ§ª Test endpoints:")
    print("  â€¢ Health: http://localhost:5000/health")
    print("  â€¢ Predict: http://localhost:5000/predict/AAPL")
    print("  â€¢ Cache: http://localhost:5000/cache/status")
    print()
    
    app.run(host='0.0.0.0', port=5000, debug=True) 